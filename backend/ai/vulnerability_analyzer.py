#!/usr/bin/env python3
"""
AI-powered vulnerability analysis system for InfoSentinel.
Implements machine learning for false positive reduction and intelligent prioritization.
"""
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.feature_extraction.text import TfidfVectorizer
import joblib
import logging
import os
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import json

logger = logging.getLogger(__name__)

class VulnerabilityAnalyzer:
    """
    AI-powered vulnerability analyzer for false positive reduction and prioritization.
    """
    
    def __init__(self, model_path: str = "models/"):
        """
        Initialize the vulnerability analyzer.
        
        Args:
            model_path: Path to store/load trained models
        """
        self.model_path = model_path
        self.false_positive_model = None
        self.priority_model = None
        self.severity_model = None
        self.text_vectorizer = None
        self.scaler = StandardScaler()
        self.label_encoders = {}
        
        # Ensure model directory exists
        os.makedirs(model_path, exist_ok=True)
        
        # Load pre-trained models if available
        self._load_models()
    
    def extract_features(self, vulnerability: Dict) -> np.ndarray:
        """
        Extract features from vulnerability data for ML analysis.
        
        Args:
            vulnerability: Vulnerability data dictionary
            
        Returns:
            Feature vector as numpy array
        """
        features = []
        
        # Basic vulnerability features
        features.extend([
            len(vulnerability.get('title', '')),
            len(vulnerability.get('description', '')),
            vulnerability.get('port', 0),
            1 if vulnerability.get('host') else 0,
            len(vulnerability.get('details', {}).get('script_output', ''))
        ])
        
        # Severity mapping
        severity_map = {'low': 1, 'medium': 2, 'high': 3, 'critical': 4}
        features.append(severity_map.get(vulnerability.get('severity', 'low'), 1))
        
        # Service-based features
        service = vulnerability.get('service', '').lower()
        common_services = ['http', 'https', 'ssh', 'ftp', 'smtp', 'dns', 'mysql', 'postgresql']
        for svc in common_services:
            features.append(1 if svc in service else 0)
        
        # CVE-based features
        cve_pattern = vulnerability.get('cve', '')
        features.extend([
            1 if 'CVE-' in cve_pattern else 0,
            len(cve_pattern.split('-')) if cve_pattern else 0
        ])
        
        # Script-based features
        script_name = vulnerability.get('script', '').lower()
        vuln_keywords = ['vuln', 'exploit', 'dos', 'injection', 'xss', 'csrf', 'auth']
        for keyword in vuln_keywords:
            features.append(1 if keyword in script_name else 0)
        
        # Time-based features
        created_at = vulnerability.get('created_at')
        if created_at:
            if isinstance(created_at, str):
                created_at = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
            features.extend([
                created_at.hour,
                created_at.weekday(),
                created_at.month
            ])
        else:
            features.extend([0, 0, 0])
        
        return np.array(features, dtype=float)
    
    def extract_text_features(self, vulnerability: Dict) -> str:
        """
        Extract text content for NLP analysis.
        
        Args:
            vulnerability: Vulnerability data dictionary
            
        Returns:
            Combined text content
        """
        text_parts = [
            vulnerability.get('title', ''),
            vulnerability.get('description', ''),
            vulnerability.get('details', {}).get('script_output', ''),
            vulnerability.get('service', ''),
            vulnerability.get('script', '')
        ]
        
        return ' '.join(filter(None, text_parts))
    
    def train_false_positive_model(self, training_data: List[Dict]) -> Dict:
        """
        Train the false positive detection model.
        
        Args:
            training_data: List of vulnerability dictionaries with 'is_false_positive' labels
            
        Returns:
            Training results and metrics
        """
        logger.info("Training false positive detection model...")
        
        # Extract features and labels
        X_numeric = []
        X_text = []
        y = []
        
        for vuln in training_data:
            if 'is_false_positive' in vuln:
                X_numeric.append(self.extract_features(vuln))
                X_text.append(self.extract_text_features(vuln))
                y.append(1 if vuln['is_false_positive'] else 0)
        
        if len(X_numeric) < 10:
            logger.warning("Insufficient training data for false positive model")
            return {'status': 'insufficient_data', 'samples': len(X_numeric)}
        
        # Convert to numpy arrays
        X_numeric = np.array(X_numeric)
        y = np.array(y)
        
        # Scale numeric features
        X_numeric_scaled = self.scaler.fit_transform(X_numeric)
        
        # Vectorize text features
        if self.text_vectorizer is None:
            self.text_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
        
        X_text_vectorized = self.text_vectorizer.fit_transform(X_text).toarray()
        
        # Combine features
        X_combined = np.hstack([X_numeric_scaled, X_text_vectorized])
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X_combined, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Train model
        self.false_positive_model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            class_weight='balanced'
        )
        
        self.false_positive_model.fit(X_train, y_train)
        
        # Evaluate model
        train_score = self.false_positive_model.score(X_train, y_train)
        test_score = self.false_positive_model.score(X_test, y_test)
        
        # Cross-validation
        cv_scores = cross_val_score(self.false_positive_model, X_combined, y, cv=5)
        
        # Predictions for detailed metrics
        y_pred = self.false_positive_model.predict(X_test)
        
        results = {
            'status': 'success',
            'training_samples': len(X_train),
            'test_samples': len(X_test),
            'train_accuracy': train_score,
            'test_accuracy': test_score,
            'cv_mean_accuracy': cv_scores.mean(),
            'cv_std_accuracy': cv_scores.std(),
            'classification_report': classification_report(y_test, y_pred, output_dict=True),
            'feature_importance': self.false_positive_model.feature_importances_[:len(X_numeric[0])].tolist()
        }
        
        # Save model
        self._save_model('false_positive_model', self.false_positive_model)
        self._save_model('text_vectorizer', self.text_vectorizer)
        self._save_model('scaler', self.scaler)
        
        logger.info(f"False positive model trained successfully. Test accuracy: {test_score:.3f}")
        
        return results
    
    def train_priority_model(self, training_data: List[Dict]) -> Dict:
        """
        Train the vulnerability prioritization model.
        
        Args:
            training_data: List of vulnerability dictionaries with 'priority_score' labels
            
        Returns:
            Training results and metrics
        """
        logger.info("Training vulnerability prioritization model...")
        
        # Extract features and labels
        X_numeric = []
        X_text = []
        y = []
        
        for vuln in training_data:
            if 'priority_score' in vuln:
                X_numeric.append(self.extract_features(vuln))
                X_text.append(self.extract_text_features(vuln))
                y.append(vuln['priority_score'])
        
        if len(X_numeric) < 10:
            logger.warning("Insufficient training data for priority model")
            return {'status': 'insufficient_data', 'samples': len(X_numeric)}
        
        # Convert to numpy arrays
        X_numeric = np.array(X_numeric)
        y = np.array(y)
        
        # Scale numeric features
        X_numeric_scaled = self.scaler.transform(X_numeric)
        
        # Vectorize text features
        X_text_vectorized = self.text_vectorizer.transform(X_text).toarray()
        
        # Combine features
        X_combined = np.hstack([X_numeric_scaled, X_text_vectorized])
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X_combined, y, test_size=0.2, random_state=42
        )
        
        # Train model
        self.priority_model = GradientBoostingClassifier(
            n_estimators=100,
            max_depth=6,
            random_state=42
        )
        
        self.priority_model.fit(X_train, y_train)
        
        # Evaluate model
        train_score = self.priority_model.score(X_train, y_train)
        test_score = self.priority_model.score(X_test, y_test)
        
        # Cross-validation
        cv_scores = cross_val_score(self.priority_model, X_combined, y, cv=5)
        
        results = {
            'status': 'success',
            'training_samples': len(X_train),
            'test_samples': len(X_test),
            'train_accuracy': train_score,
            'test_accuracy': test_score,
            'cv_mean_accuracy': cv_scores.mean(),
            'cv_std_accuracy': cv_scores.std(),
            'feature_importance': self.priority_model.feature_importances_[:len(X_numeric[0])].tolist()
        }
        
        # Save model
        self._save_model('priority_model', self.priority_model)
        
        logger.info(f"Priority model trained successfully. Test accuracy: {test_score:.3f}")
        
        return results
    
    def predict_false_positive(self, vulnerability: Dict) -> Dict:
        """
        Predict if a vulnerability is a false positive.
        
        Args:
            vulnerability: Vulnerability data dictionary
            
        Returns:
            Prediction results with confidence score
        """
        if self.false_positive_model is None:
            return {'error': 'False positive model not trained'}
        
        try:
            # Extract features
            X_numeric = self.extract_features(vulnerability).reshape(1, -1)
            X_text = self.extract_text_features(vulnerability)
            
            # Scale and vectorize
            X_numeric_scaled = self.scaler.transform(X_numeric)
            X_text_vectorized = self.text_vectorizer.transform([X_text]).toarray()
            
            # Combine features
            X_combined = np.hstack([X_numeric_scaled, X_text_vectorized])
            
            # Make prediction
            prediction = self.false_positive_model.predict(X_combined)[0]
            confidence = self.false_positive_model.predict_proba(X_combined)[0]
            
            return {
                'is_false_positive': bool(prediction),
                'confidence': float(confidence[1] if prediction else confidence[0]),
                'false_positive_probability': float(confidence[1]),
                'true_positive_probability': float(confidence[0])
            }
            
        except Exception as e:
            logger.error(f"Error predicting false positive: {str(e)}")
            return {'error': str(e)}
    
    def predict_priority(self, vulnerability: Dict) -> Dict:
        """
        Predict vulnerability priority score.
        
        Args:
            vulnerability: Vulnerability data dictionary
            
        Returns:
            Priority prediction results
        """
        if self.priority_model is None:
            return {'error': 'Priority model not trained'}
        
        try:
            # Extract features
            X_numeric = self.extract_features(vulnerability).reshape(1, -1)
            X_text = self.extract_text_features(vulnerability)
            
            # Scale and vectorize
            X_numeric_scaled = self.scaler.transform(X_numeric)
            X_text_vectorized = self.text_vectorizer.transform([X_text]).toarray()
            
            # Combine features
            X_combined = np.hstack([X_numeric_scaled, X_text_vectorized])
            
            # Make prediction
            priority_score = self.priority_model.predict(X_combined)[0]
            confidence = self.priority_model.predict_proba(X_combined)[0]
            
            return {
                'priority_score': int(priority_score),
                'confidence': float(confidence.max()),
                'priority_distribution': confidence.tolist()
            }
            
        except Exception as e:
            logger.error(f"Error predicting priority: {str(e)}")
            return {'error': str(e)}
    
    def analyze_vulnerability(self, vulnerability: Dict) -> Dict:
        """
        Comprehensive AI analysis of a vulnerability.
        
        Args:
            vulnerability: Vulnerability data dictionary
            
        Returns:
            Complete analysis results
        """
        analysis = {
            'vulnerability_id': vulnerability.get('_id'),
            'analyzed_at': datetime.utcnow().isoformat(),
            'ai_analysis': {}
        }
        
        # False positive analysis
        fp_result = self.predict_false_positive(vulnerability)
        analysis['ai_analysis']['false_positive'] = fp_result
        
        # Priority analysis
        priority_result = self.predict_priority(vulnerability)
        analysis['ai_analysis']['priority'] = priority_result
        
        # Risk assessment
        risk_score = self._calculate_risk_score(vulnerability, fp_result, priority_result)
        analysis['ai_analysis']['risk_assessment'] = risk_score
        
        # Remediation suggestions
        remediation = self._generate_remediation_suggestions(vulnerability)
        analysis['ai_analysis']['remediation'] = remediation
        
        return analysis
    
    def _calculate_risk_score(self, vulnerability: Dict, fp_result: Dict, priority_result: Dict) -> Dict:
        """
        Calculate comprehensive risk score.
        
        Args:
            vulnerability: Vulnerability data
            fp_result: False positive prediction
            priority_result: Priority prediction
            
        Returns:
            Risk assessment dictionary
        """
        # Base severity score
        severity_map = {'low': 25, 'medium': 50, 'high': 75, 'critical': 100}
        base_score = severity_map.get(vulnerability.get('severity', 'low'), 25)
        
        # Adjust for false positive probability
        fp_adjustment = 1 - fp_result.get('false_positive_probability', 0)
        
        # Adjust for priority
        priority_multiplier = priority_result.get('priority_score', 1) / 5.0
        
        # Calculate final risk score
        risk_score = base_score * fp_adjustment * priority_multiplier
        
        # Determine risk level
        if risk_score >= 80:
            risk_level = 'critical'
        elif risk_score >= 60:
            risk_level = 'high'
        elif risk_score >= 40:
            risk_level = 'medium'
        else:
            risk_level = 'low'
        
        return {
            'risk_score': round(risk_score, 2),
            'risk_level': risk_level,
            'confidence': min(fp_result.get('confidence', 0.5), priority_result.get('confidence', 0.5)),
            'factors': {
                'base_severity': base_score,
                'false_positive_adjustment': fp_adjustment,
                'priority_multiplier': priority_multiplier
            }
        }
    
    def _generate_remediation_suggestions(self, vulnerability: Dict) -> Dict:
        """
        Generate AI-powered remediation suggestions.
        
        Args:
            vulnerability: Vulnerability data
            
        Returns:
            Remediation suggestions
        """
        suggestions = {
            'immediate_actions': [],
            'long_term_actions': [],
            'prevention_measures': [],
            'confidence': 0.8
        }
        
        # Analyze vulnerability type and generate suggestions
        title = vulnerability.get('title', '').lower()
        service = vulnerability.get('service', '').lower()
        port = vulnerability.get('port', 0)
        
        # SQL Injection
        if any(keyword in title for keyword in ['sql', 'injection', 'sqli']):
            suggestions['immediate_actions'].extend([
                'Implement parameterized queries',
                'Enable SQL injection detection in WAF',
                'Review and sanitize all user inputs'
            ])
            suggestions['long_term_actions'].extend([
                'Conduct code review for all database interactions',
                'Implement stored procedures where applicable',
                'Regular security training for developers'
            ])
        
        # XSS vulnerabilities
        if any(keyword in title for keyword in ['xss', 'cross-site', 'scripting']):
            suggestions['immediate_actions'].extend([
                'Implement output encoding',
                'Enable Content Security Policy (CSP)',
                'Validate and sanitize user inputs'
            ])
            suggestions['long_term_actions'].extend([
                'Use secure templating engines',
                'Regular security code reviews',
                'Implement input validation framework'
            ])
        
        # Authentication issues
        if any(keyword in title for keyword in ['auth', 'login', 'password', 'credential']):
            suggestions['immediate_actions'].extend([
                'Implement strong password policies',
                'Enable multi-factor authentication',
                'Review authentication mechanisms'
            ])
            suggestions['long_term_actions'].extend([
                'Implement SSO where appropriate',
                'Regular access reviews',
                'Security awareness training'
            ])
        
        # Service-specific suggestions
        if 'ssh' in service:
            suggestions['immediate_actions'].extend([
                'Disable password authentication',
                'Use key-based authentication only',
                'Change default SSH port'
            ])
        
        if 'http' in service and port in [80, 8080]:
            suggestions['immediate_actions'].extend([
                'Implement HTTPS encryption',
                'Configure security headers',
                'Enable HSTS'
            ])
        
        # Generic prevention measures
        suggestions['prevention_measures'].extend([
            'Regular security assessments',
            'Keep software and systems updated',
            'Implement network segmentation',
            'Monitor and log security events',
            'Regular backup and recovery testing'
        ])
        
        return suggestions
    
    def _save_model(self, name: str, model) -> None:
        """
        Save a trained model to disk.
        
        Args:
            name: Model name
            model: Model object to save
        """
        try:
            model_file = os.path.join(self.model_path, f"{name}.joblib")
            joblib.dump(model, model_file)
            logger.info(f"Model saved: {model_file}")
        except Exception as e:
            logger.error(f"Error saving model {name}: {str(e)}")
    
    def _load_models(self) -> None:
        """
        Load pre-trained models from disk.
        """
        models_to_load = [
            ('false_positive_model', 'false_positive_model'),
            ('priority_model', 'priority_model'),
            ('text_vectorizer', 'text_vectorizer'),
            ('scaler', 'scaler')
        ]
        
        for attr_name, file_name in models_to_load:
            try:
                model_file = os.path.join(self.model_path, f"{file_name}.joblib")
                if os.path.exists(model_file):
                    setattr(self, attr_name, joblib.load(model_file))
                    logger.info(f"Loaded model: {file_name}")
            except Exception as e:
                logger.warning(f"Could not load model {file_name}: {str(e)}")
    
    def get_model_status(self) -> Dict:
        """
        Get the status of all AI models.
        
        Returns:
            Model status information
        """
        return {
            'false_positive_model': self.false_positive_model is not None,
            'priority_model': self.priority_model is not None,
            'text_vectorizer': self.text_vectorizer is not None,
            'scaler': self.scaler is not None,
            'model_path': self.model_path,
            'ready_for_analysis': all([
                self.false_positive_model is not None,
                self.text_vectorizer is not None,
                self.scaler is not None
            ])
        }
    
    def analyze_findings(self, findings: List[Dict], target: str) -> List[Dict]:
        """
        Analyze vulnerability findings with AI to reduce false positives and prioritize.
        
        Args:
            findings: List of vulnerability findings
            target: Target being scanned
            
        Returns:
            Analyzed and prioritized findings
        """
        if not findings:
            return findings
            
        analyzed_findings = []
        
        for finding in findings:
            try:
                # Extract features for analysis
                features = self.extract_features(finding)
                
                # Predict false positive probability if model is available
                if self.false_positive_model and self.text_vectorizer and self.scaler:
                    text_features = self.extract_text_features(finding)
                    text_vectorized = self.text_vectorizer.transform([text_features]).toarray()
                    features_scaled = self.scaler.transform([features])
                    combined_features = np.hstack([features_scaled, text_vectorized])
                    
                    fp_probability = self.false_positive_model.predict_proba(combined_features)[0][1]
                    finding['false_positive_probability'] = float(fp_probability)
                    finding['confidence_score'] = 1.0 - fp_probability
                else:
                    # Default confidence based on severity and CVE presence
                    severity_confidence = {
                        'critical': 0.9,
                        'high': 0.8,
                        'medium': 0.6,
                        'low': 0.4
                    }
                    base_confidence = severity_confidence.get(finding.get('severity', 'low'), 0.4)
                    
                    # Boost confidence if CVE is present
                    if finding.get('cve'):
                        base_confidence = min(0.95, base_confidence + 0.2)
                    
                    finding['confidence_score'] = base_confidence
                    finding['false_positive_probability'] = 1.0 - base_confidence
                
                # Calculate priority score
                priority_score = self._calculate_priority_score(finding)
                finding['priority_score'] = priority_score
                
                # Add AI analysis metadata
                finding['ai_analysis'] = {
                    'analyzed_at': datetime.utcnow().isoformat(),
                    'analyzer_version': '1.0',
                    'target': target
                }
                
                analyzed_findings.append(finding)
                
            except Exception as e:
                logger.error(f"Error analyzing finding: {e}")
                # Keep original finding if analysis fails
                analyzed_findings.append(finding)
        
        # Sort by priority score (highest first)
        analyzed_findings.sort(key=lambda x: x.get('priority_score', 0), reverse=True)
        
        logger.info(f"Analyzed {len(analyzed_findings)} findings for target {target}")
        return analyzed_findings
    
    def _calculate_priority_score(self, finding: Dict) -> float:
        """
        Calculate priority score for a finding.
        
        Args:
            finding: Vulnerability finding
            
        Returns:
            Priority score (0-100)
        """
        score = 0.0
        
        # Base score from severity
        severity_scores = {
            'critical': 40,
            'high': 30,
            'medium': 20,
            'low': 10
        }
        score += severity_scores.get(finding.get('severity', 'low'), 10)
        
        # Confidence boost
        confidence = finding.get('confidence_score', 0.5)
        score += confidence * 30
        
        # CVE presence boost
        if finding.get('cve'):
            score += 15
        
        # Exploit availability boost
        if finding.get('exploit_available'):
            score += 10
        
        # Service criticality (common services get higher scores)
        service = finding.get('service', '').lower()
        critical_services = ['http', 'https', 'ssh', 'ftp', 'smtp', 'mysql', 'postgresql']
        if any(svc in service for svc in critical_services):
            score += 5
        
        return min(100.0, score)